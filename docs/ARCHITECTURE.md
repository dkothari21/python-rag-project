# ğŸ—ï¸ Architecture Deep Dive

This document provides a deeper look at how the RAG system works, explaining each component and how data flows through the system.

---

## System Architecture Diagram

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚          python-rag-project          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                      â”‚
              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚  INGESTION â”‚                        â”‚   QUERYING   â”‚
              â”‚  PIPELINE  â”‚                        â”‚   PIPELINE   â”‚
              â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                                      â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚          â”‚           â”‚           â”‚              â”‚              â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ Load   â”‚ â”‚ Split  â”‚ â”‚ Create â”‚  â”‚ Embed   â”‚  â”‚ Search  â”‚  â”‚ Generate â”‚
    â”‚ Docs   â”‚ â”‚ Chunks â”‚ â”‚ Embeds â”‚  â”‚ Questionâ”‚  â”‚ ChromaDBâ”‚  â”‚ Answer   â”‚
    â”‚        â”‚ â”‚        â”‚ â”‚ & Storeâ”‚  â”‚         â”‚  â”‚         â”‚  â”‚ (Gemini) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component Details

### 1. Configuration Layer (`src/config.py`)

```
Environment (.env)  â”€â”€â–¶  load_dotenv()  â”€â”€â–¶  Python Variables
                                              â”‚
                                              â”œâ”€â”€ GOOGLE_API_KEY
                                              â”œâ”€â”€ LLM_MODEL
                                              â”œâ”€â”€ EMBEDDING_MODEL
                                              â”œâ”€â”€ CHUNK_SIZE
                                              â”œâ”€â”€ CHUNK_OVERLAP
                                              â”œâ”€â”€ TOP_K_RESULTS
                                              â””â”€â”€ CHROMA_DB_DIR
```

**Why centralize config?**
- Change settings in **one place**, affects the entire app
- **Secrets stay in `.env`**, never in code
- Easy to switch models or tune parameters

---

### 2. Document Ingestion Pipeline

#### Step 1: Load Documents (`document_loader.py â†’ load_documents()`)

```
data/sample_docs/
â”œâ”€â”€ python_basics.txt  â”€â”€â–¶  TextLoader   â”€â”€â–¶  Document object
â””â”€â”€ ai_ml_basics.txt   â”€â”€â–¶  TextLoader   â”€â”€â–¶  Document object
```

Each **Document** object contains:
- `page_content`: The actual text
- `metadata`: Information about the source (filename, path)

#### Step 2: Split into Chunks (`document_loader.py â†’ split_documents()`)

```
Original Document (2000 chars)
â”‚
â”œâ”€â”€ Chunk 1: chars 0-500
â”œâ”€â”€ Chunk 2: chars 400-900     â† 100 char overlap with Chunk 1
â”œâ”€â”€ Chunk 3: chars 800-1300    â† 100 char overlap with Chunk 2
â”œâ”€â”€ Chunk 4: chars 1200-1700   â† 100 char overlap with Chunk 3
â””â”€â”€ Chunk 5: chars 1600-2000   â† 100 char overlap with Chunk 4
```

**Why overlap?** Consider this text split at position 500:

```
Chunk 1: "...Python uses try-except blocks for"
Chunk 2: "error handling. The syntax is..."
```

Without overlap, searching for "try-except error handling" might miss both chunks. With overlap, Chunk 2 would also contain "try-except blocks for error handling."

#### Step 3: Create Embeddings & Store (`vector_store.py â†’ create_vector_store()`)

```
Text Chunk                          Embedding (Vector)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚"Python lists â”‚   Gemini          â”‚[0.12, -0.45, 0.78,    â”‚
â”‚ are ordered  â”‚ â”€â”€Embeddingâ”€â”€â–¶    â”‚ 0.33, -0.21, 0.56,    â”‚
â”‚ collections" â”‚   Model           â”‚ ..., 0.89]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                            â–¼
                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                     â”‚   ChromaDB    â”‚
                                     â”‚  (Local Disk) â”‚
                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 3. Query Pipeline

#### Step 1: Embed the Question

```
"What is a list?"  â”€â”€â–¶  Gemini Embedding  â”€â”€â–¶  [0.15, -0.42, 0.81, ...]
```

#### Step 2: Similarity Search

```
Question Vector: [0.15, -0.42, 0.81, ...]

ChromaDB compares against all stored vectors:

Chunk 1 Vector: [0.12, -0.45, 0.78, ...]  â† Distance: 0.05 (VERY similar!) âœ…
Chunk 2 Vector: [0.89, 0.23, -0.61, ...]  â† Distance: 0.82 (not similar)
Chunk 3 Vector: [0.11, -0.40, 0.75, ...]  â† Distance: 0.08 (similar!) âœ…
Chunk 4 Vector: [-0.56, 0.71, 0.12, ...]  â† Distance: 0.91 (not similar)
Chunk 5 Vector: [0.14, -0.38, 0.80, ...]  â† Distance: 0.06 (similar!) âœ…

Top 3 results returned (lowest distance = most similar)
```

#### Step 3: Build Prompt with Context

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 PROMPT TO GEMINI                    â”‚
â”‚                                                    â”‚
â”‚  System: You are a helpful assistant that answers  â”‚
â”‚  questions based on the provided context.          â”‚
â”‚                                                    â”‚
â”‚  CONTEXT:                                          â”‚
â”‚  [Chunk 1 text]                                    â”‚
â”‚  [Chunk 3 text]                                    â”‚
â”‚  [Chunk 5 text]                                    â”‚
â”‚                                                    â”‚
â”‚  QUESTION: What is a list in Python?               â”‚
â”‚                                                    â”‚
â”‚  ANSWER:                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Step 4: Gemini Generates Answer

Gemini reads the context chunks and the question, then generates an answer that is **grounded in your documents** rather than making things up.

---

## Data Flow Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Documentsâ”‚â”€â”€â–¶â”‚ Text       â”‚â”€â”€â–¶â”‚ Embeddingâ”‚â”€â”€â–¶â”‚ ChromaDB â”‚â”€â”€â–¶â”‚ Retrieverâ”‚
â”‚ (.txt,   â”‚   â”‚ Chunks     â”‚   â”‚ Vectors  â”‚   â”‚ Storage  â”‚   â”‚ Search   â”‚
â”‚  .pdf)   â”‚   â”‚ (500 chars)â”‚   â”‚ (numbers)â”‚   â”‚ (local)  â”‚   â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                                                                      â”‚
                                                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Final    â”‚â—€â”€â”€â”‚ Gemini LLM â”‚â—€â”€â”€â”‚ Prompt + â”‚â—€â”€â”€â”‚ Top K    â”‚â—€â”€â”€â”‚ Question â”‚
â”‚ Answer   â”‚   â”‚ Generation â”‚   â”‚ Context  â”‚   â”‚ Chunks   â”‚   â”‚ Embeddingâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Technology Choices & Why

| Technology | Purpose | Why This Choice? |
|-----------|---------|------------------|
| **Python** | Language | Most popular for AI/ML, rich ecosystem |
| **Google Gemini** | LLM + Embeddings | Free tier, powerful, single API for both |
| **ChromaDB** | Vector Database | Local (no account), easy setup, beginner-friendly |
| **LangChain** | Framework | Simplifies RAG pipeline, huge community |
| **python-dotenv** | Config | Industry standard for managing secrets |

---

## Configuration Tuning Guide

| Setting | Default | Effect of Increasing | Effect of Decreasing |
|---------|---------|---------------------|---------------------|
| `CHUNK_SIZE` | 500 | Broader context per chunk, less precise | More precise chunks, might lose context |
| `CHUNK_OVERLAP` | 100 | Better continuity, slightly more storage | Might miss info at boundaries |
| `TOP_K_RESULTS` | 3 | More context for LLM, slower, may add noise | Faster, more focused, might miss info |
| `temperature` | 0.3 | More creative/varied answers | More focused/deterministic answers |

---

## Security Notes

1. **API Key** â€” Never commit your `.env` file. The `.gitignore` handles this.
2. **ChromaDB** â€” Data is stored locally in `chroma_db/`. Don't commit this to GitHub if it contains sensitive data.
3. **Documents** â€” Be mindful of what documents you add. They are processed and stored locally.
